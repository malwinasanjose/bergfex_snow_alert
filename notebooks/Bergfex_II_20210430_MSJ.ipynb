{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bergfex Webscraping\n",
    "<b> Milestone 2</b> \n",
    "\n",
    "Scraping the snow level data from meteocentrale.ch website in order to create Pandas dataframes that contain the snow level for 91 weather stations around Switzerland.\n",
    "This code uses BeautifulSoup to parse the html tags. A for-loop iterates over each html tag and adds the corresponding information into empty lists. Afterwards the data is cleaned.\n",
    "Finally, we add the GPS coordinates of each weather station, from two databases containing geodata of Swiss cities and ski resorts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unhash and run the below line once\n",
    "#conda install -c anaconda beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Scraping: snow information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same packages as in notebook I to scrape the meteocentrale website, which contains information for around 80 locations in Switzerland with local snow thickness measurements updated every day at 7 AM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# Initializing the future colums of our dataframe with empty lists\n",
    "\n",
    "snowlevel = []  # height in cm\n",
    "location = []  # town and elevation of town\n",
    "\n",
    "# Only scrape one page (no looping over several pages necessary as not so many data points available)\n",
    "link = 'http://www.meteocentrale.ch/de/wetter/hitlisten/schneehoehen.html'\n",
    "page = requests.get(link, timeout=10)\n",
    "print(page.status_code)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")  # bs4.BeautifulSoup object\n",
    "hitlist = soup.findAll('table', {'class': 'hitlist'})  #bs4.element.ResultSet\n",
    "\n",
    "# If '200' then the scraping was successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extracting the necessary information\n",
    "Village Name, Elevation, Snow Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>snowlevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grimsel-Hospiz, 1980 m</td>\n",
       "      <td>264 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weissfluhjoch, 2690 m</td>\n",
       "      <td>236 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Corvatsch, 3315 m</td>\n",
       "      <td>164 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gütsch/Andermatt, 2282 m</td>\n",
       "      <td>144 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Corviglia, 2497 m</td>\n",
       "      <td>78 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Zernez, 1478 m</td>\n",
       "      <td>0 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Zollikofen, 553 m</td>\n",
       "      <td>0 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Zürich-Affoltern, 443 m</td>\n",
       "      <td>0 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Zürich-Flughafen, 432 m</td>\n",
       "      <td>0 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Zürich-Fluntern (SMA), 556 m</td>\n",
       "      <td>0 cm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        location snowlevel\n",
       "0         Grimsel-Hospiz, 1980 m    264 cm\n",
       "1          Weissfluhjoch, 2690 m    236 cm\n",
       "2              Corvatsch, 3315 m    164 cm\n",
       "3       Gütsch/Andermatt, 2282 m    144 cm\n",
       "4              Corviglia, 2497 m     78 cm\n",
       "..                           ...       ...\n",
       "78                Zernez, 1478 m      0 cm\n",
       "79             Zollikofen, 553 m      0 cm\n",
       "80       Zürich-Affoltern, 443 m      0 cm\n",
       "81       Zürich-Flughafen, 432 m      0 cm\n",
       "82  Zürich-Fluntern (SMA), 556 m      0 cm\n",
       "\n",
       "[83 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get location name\n",
    "location_item = hitlist[0].findAll('a')\n",
    "location.append([info.get_text().strip() for info in location_item])\n",
    "loc = location[0]\n",
    "\n",
    "# Get snowlevel\n",
    "snowlevel_item = hitlist[0].findAll('td', {'class': 'value'}) \n",
    "snowlevel.append([info.get_text().strip() for info in snowlevel_item])\n",
    "snow = snowlevel[0]\n",
    "\n",
    "# Combine into DF\n",
    "heights_df = pd.DataFrame({'location': loc,'snowlevel': snow})\n",
    "heights_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>height_in_m</th>\n",
       "      <th>snowlevel_in_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grimsel-Hospiz</td>\n",
       "      <td>1980</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weissfluhjoch</td>\n",
       "      <td>2690</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Corvatsch</td>\n",
       "      <td>3315</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gütsch/Andermatt</td>\n",
       "      <td>2282</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Corviglia</td>\n",
       "      <td>2497</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           location height_in_m  snowlevel_in_cm\n",
       "0    Grimsel-Hospiz        1980              264\n",
       "1     Weissfluhjoch        2690              236\n",
       "2         Corvatsch        3315              164\n",
       "3  Gütsch/Andermatt        2282              144\n",
       "4         Corviglia        2497               78"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove cm, convert to 'int'\n",
    "heights_df['snowlevel_in_cm']=pd.Series(heights_df['snowlevel']).str.replace(\" cm\", '')\n",
    "heights_df['snowlevel_in_cm']=pd.Series(heights_df['snowlevel_in_cm']).astype(int)\n",
    "\n",
    "# Split location into 'village' and 'elevation of village' and merge with previous DF\n",
    "split_loc = pd.Series(heights_df['location']).str.split(',',n=2,expand = True)\n",
    "merged_df = pd.merge(heights_df, split_loc, left_index=True, right_index=True)\n",
    "\n",
    "# Drop unused columns, rename final columns, remove unit, sort columns\n",
    "intermediate_df = merged_df.iloc[:,[2,3,4]].copy()\n",
    "intermediate_df.columns = ['snowlevel_in_cm', 'location', 'height_in_m']\n",
    "intermediate_df['height_in_m']=pd.Series(intermediate_df['height_in_m']).str.replace(\" m\", '')\n",
    "snow_level_df = pd.DataFrame(intermediate_df, columns = ['location', 'height_in_m', 'snowlevel_in_cm'])\n",
    "snow_level_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the file_path to your path if necessary\n",
    "file_path = '../data/'\n",
    "snow_level_df.to_csv(file_path + 'snow_level_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Adding Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching the snow level observation station with GPS coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to get the coordinates for each snow observation station (for which we have the name of the locality)\n",
    "\n",
    "We use two sources (all coordinates are given in geographical coordinate system EPSG:4326/WGS84): \n",
    "\n",
    " - 1/ from World Cities Database, which contains most large cities in Switzerland and geographic info saved as swiss_cities.csv\n",
    "       https://simplemaps.com/data/ch-cities\n",
    " - 2/ Ski resort coordinates, for the smaller but more relevant localities in mountaineous areas. Those were collected as an initial csv file from skiresort.info (this dataset is not available online anymore), and missing data was collected manually from Wikipedia.org. The resulting file was saved as ski.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning of dataframes: this step needs to be adapted to data sources and csv content. \n",
    "# Here the swiss_cities files were overwritten with the cleaned up version, so no need to run the following steps\n",
    "\n",
    "file_path = '../data/' # change to your local folder\n",
    "\n",
    "# swiss_cities should have index, city, lat, lng columns (if not, uncomment the cleaning lines)\n",
    "swiss_cities = pd.read_csv((file_path + 'swiss_cities.csv')) \n",
    "# ski_resorts should have index, city, lat, lng columns (if not, uncomment the cleaning lines)\n",
    "ski_resorts = pd.read_csv((file_path + 'ski.csv'))\n",
    "\n",
    "## swiss_cities cleaning (uncomment if necessary)\n",
    "# swiss_cities = swiss_cities.drop(columns ={'iso2', 'country', 'capital', 'population', 'population_proper', 'admin_name'})\n",
    "swiss_cities = swiss_cities[['city', 'lat', 'lng']]\n",
    "\n",
    "## ski_resorts cleaning\n",
    "# ski_resorts should have index, lng, lat, city columns\n",
    "ski_resorts = ski_resorts.rename(columns = {'X':'lng', 'Y':'lat', 'Name': 'city'})\n",
    "ski_resorts = ski_resorts.drop(columns = {'description'})\n",
    "ski_resorts = ski_resorts[['city', 'lat', 'lng']]\n",
    "\n",
    "\n",
    "# merging the two dataframes by concatenating them vertically\n",
    "cities_ski = pd.concat([swiss_cities, ski_resorts], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 177 entries, 0 to 176\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   city    177 non-null    object \n",
      " 1   lat     177 non-null    float64\n",
      " 2   lng     177 non-null    float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 4.3+ KB\n"
     ]
    }
   ],
   "source": [
    "cities_ski.info() # should have 177 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the dataframe as city_coord\n",
    "cities_ski.to_csv(file_path +'cities_ski_coord.csv', index = False) # has city, lat long in it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we still need to match the snow observation locations to the place's coordinated. We do that by merging the corresponding dataframes on the location names. Data will be lost when the names are not matching exaclty. As the number of errors is quite small (and we didn't know about regex yet), we dealt with that problem by filling the missing data by hand, and the complete dataframe for notebook is saved as snow_coordinates.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>height_in_m</th>\n",
       "      <th>snowlevel_in_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La Chaux-de-Fonds</td>\n",
       "      <td>47.099600</td>\n",
       "      <td>6.829600</td>\n",
       "      <td>1019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chur</td>\n",
       "      <td>46.852100</td>\n",
       "      <td>9.529700</td>\n",
       "      <td>555</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wädenswil</td>\n",
       "      <td>47.230300</td>\n",
       "      <td>8.672200</td>\n",
       "      <td>463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nyon</td>\n",
       "      <td>46.382000</td>\n",
       "      <td>6.238900</td>\n",
       "      <td>430</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Davos</td>\n",
       "      <td>46.809100</td>\n",
       "      <td>9.839800</td>\n",
       "      <td>1590</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sursee</td>\n",
       "      <td>47.174200</td>\n",
       "      <td>8.108100</td>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Altdorf</td>\n",
       "      <td>46.880600</td>\n",
       "      <td>8.639400</td>\n",
       "      <td>449</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Arosa</td>\n",
       "      <td>46.789611</td>\n",
       "      <td>9.638778</td>\n",
       "      <td>1878</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Braunwald</td>\n",
       "      <td>46.938250</td>\n",
       "      <td>8.987139</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Engelberg</td>\n",
       "      <td>46.790917</td>\n",
       "      <td>8.387722</td>\n",
       "      <td>1035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lenzerheide</td>\n",
       "      <td>46.746889</td>\n",
       "      <td>9.511556</td>\n",
       "      <td>1484</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Meiringen</td>\n",
       "      <td>46.737861</td>\n",
       "      <td>8.257361</td>\n",
       "      <td>595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Zermatt</td>\n",
       "      <td>45.983056</td>\n",
       "      <td>7.782167</td>\n",
       "      <td>1638</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             location        lat       lng height_in_m  snowlevel_in_cm\n",
       "0   La Chaux-de-Fonds  47.099600  6.829600        1019                1\n",
       "1                Chur  46.852100  9.529700         555                0\n",
       "2           Wädenswil  47.230300  8.672200         463                0\n",
       "3                Nyon  46.382000  6.238900         430                0\n",
       "4               Davos  46.809100  9.839800        1590               19\n",
       "5              Sursee  47.174200  8.108100         510                0\n",
       "6             Altdorf  46.880600  8.639400         449                0\n",
       "7               Arosa  46.789611  9.638778        1878               48\n",
       "9           Braunwald  46.938250  8.987139        None               11\n",
       "11          Engelberg  46.790917  8.387722        1035                0\n",
       "13        Lenzerheide  46.746889  9.511556        1484               14\n",
       "15          Meiringen  46.737861  8.257361         595                0\n",
       "17            Zermatt  45.983056  7.782167        1638                0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merging city_coordinates with snow data to create snow_coordinates_demo\n",
    "# this is a dummy df that only contains limited data for demonstration purposes. \n",
    "# In the next notebook we will use the actual snow_coordinates df\n",
    "\n",
    "snow_level_coord = cities_ski.merge(snow_level_df, left_on = 'city', right_on= 'location')\n",
    "snow_level_coord = snow_level_coord.drop_duplicates('city', keep='first').drop('city', 1)\n",
    "snow_level_coord = snow_level_coord[['location', 'lat', 'lng', 'height_in_m', 'snowlevel_in_cm']]\n",
    "snow_level_coord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the file_path to your path if necessary\n",
    "#file_path = '../data/'\n",
    "snow_level_coord.to_csv(file_path + 'snow_coordinates_demo.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTINUE IN NOTEBOOK III"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
