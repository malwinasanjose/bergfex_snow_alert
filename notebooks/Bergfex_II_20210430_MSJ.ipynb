{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bergfex Webscraping\n",
    "<b> Milestone 2</b> \n",
    "\n",
    "Scraping the snow level data from meteocentrale.ch website in order to create Pandas dataframes that contain the snow level for 91 weather stations around Switzerland.\n",
    "This code uses BeautifulSoup to parse the html tags. A for-loop iterates over each html tag and adds the corresponding information into empty lists. Afterwards the data is cleaned.\n",
    "Finally, we add the GPS coordinates of each weather station, from two databases containing geodata of Swiss cities and ski resorts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unhash and run the below line once\n",
    "#conda install -c anaconda beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Still to do:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DONE: check vs. NB III if anything missing\n",
    "- wip: go through comments\n",
    "- add coordinates part for snow points\n",
    "- potentially check out other weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data Scraping: snow information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# Initializing the future colums of our dataframe with empty lists\n",
    "\n",
    "snowlevel = []  # height in cm\n",
    "location = []  # town and elevation of town\n",
    "\n",
    "# Only scrape one page (no looping over several pages necessary as not so many data points available)\n",
    "link = 'http://www.meteocentrale.ch/de/wetter/hitlisten/schneehoehen.html'\n",
    "page = requests.get(link, timeout=10)\n",
    "print(page.status_code)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")  # bs4.BeautifulSoup object\n",
    "hitlist = soup.findAll('table', {'class': 'hitlist'})  #bs4.element.ResultSet\n",
    "\n",
    "# If '200' then the scraping was successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Extracting the necessary information\n",
    "Village Name, Elevation, Snow Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>snowlevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grimsel-Hospiz, 1980 m</td>\n",
       "      <td>249 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weissfluhjoch, 2690 m</td>\n",
       "      <td>230 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glattalp, 1858 m</td>\n",
       "      <td>223 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Les Attelas, 2733 m</td>\n",
       "      <td>142 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Corvatsch, 3315 m</td>\n",
       "      <td>137 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Zernez, 1478 m</td>\n",
       "      <td>0 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Zollikofen, 553 m</td>\n",
       "      <td>0 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Zürich-Affoltern, 443 m</td>\n",
       "      <td>0 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Zürich-Flughafen, 432 m</td>\n",
       "      <td>0 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Zürich-Fluntern (SMA), 556 m</td>\n",
       "      <td>0 cm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         location snowlevel\n",
       "0          Grimsel-Hospiz, 1980 m    249 cm\n",
       "1           Weissfluhjoch, 2690 m    230 cm\n",
       "2                Glattalp, 1858 m    223 cm\n",
       "3             Les Attelas, 2733 m    142 cm\n",
       "4               Corvatsch, 3315 m    137 cm\n",
       "..                            ...       ...\n",
       "96                 Zernez, 1478 m      0 cm\n",
       "97              Zollikofen, 553 m      0 cm\n",
       "98        Zürich-Affoltern, 443 m      0 cm\n",
       "99        Zürich-Flughafen, 432 m      0 cm\n",
       "100  Zürich-Fluntern (SMA), 556 m      0 cm\n",
       "\n",
       "[101 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get location name\n",
    "location_item = hitlist[0].findAll('a')\n",
    "location.append([info.get_text().strip() for info in location_item])\n",
    "loc = location[0]\n",
    "\n",
    "# Get snowlevel\n",
    "snowlevel_item = hitlist[0].findAll('td', {'class': 'value'}) \n",
    "snowlevel.append([info.get_text().strip() for info in snowlevel_item])\n",
    "snow = snowlevel[0]\n",
    "\n",
    "# Combine into DF\n",
    "heights_df = pd.DataFrame({'location': loc,'snowlevel': snow})\n",
    "heights_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>height_in_m</th>\n",
       "      <th>snowlevel_in_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grimsel-Hospiz</td>\n",
       "      <td>1980</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weissfluhjoch</td>\n",
       "      <td>2690</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glattalp</td>\n",
       "      <td>1858</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Les Attelas</td>\n",
       "      <td>2733</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Corvatsch</td>\n",
       "      <td>3315</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         location height_in_m  snowlevel_in_cm\n",
       "0  Grimsel-Hospiz        1980              249\n",
       "1   Weissfluhjoch        2690              230\n",
       "2        Glattalp        1858              223\n",
       "3     Les Attelas        2733              142\n",
       "4       Corvatsch        3315              137"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove cm, convert to 'int'\n",
    "heights_df['snowlevel_in_cm']=pd.Series(heights_df['snowlevel']).str.replace(\" cm\", '')\n",
    "heights_df['snowlevel_in_cm']=pd.Series(heights_df['snowlevel_in_cm']).astype(int)\n",
    "\n",
    "# Split location into 'village' and 'elevation of village' and merge with previous DF\n",
    "split_loc = pd.Series(heights_df['location']).str.split(',',n=2,expand = True)\n",
    "merged_df = pd.merge(heights_df, split_loc, left_index=True, right_index=True)\n",
    "\n",
    "# Drop unused columns, rename final columns, remove unit, sort columns\n",
    "intermediate_df = merged_df.iloc[:,[2,3,4]].copy()\n",
    "intermediate_df.columns = ['snowlevel_in_cm', 'location', 'height_in_m']\n",
    "intermediate_df['height_in_m']=pd.Series(intermediate_df['height_in_m']).str.replace(\" m\", '')\n",
    "snow_level_df = pd.DataFrame(intermediate_df, columns = ['location', 'height_in_m', 'snowlevel_in_cm'])\n",
    "snow_level_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the file_path to your path if necessary\n",
    "file_path = '../data'\n",
    "snow_level_df.to_csv(file_path + 'snow_level_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Adding Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching the snow level observation station with GPS coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to get the coordinates for each snow observation station (for which we have the name of the locality)\n",
    "\n",
    "We use two sources (all coordinates are given in geographical coordinate system EPSG:4326/WGS84): \n",
    "\n",
    " - 1/ from World Cities Database, which contains most large cities in Switzerland and geographic info saved as swiss_cities.csv\n",
    "       https://simplemaps.com/data/ch-cities\n",
    " - 2/ Ski resort coordinates, for the smaller but more relevant localities in mountaineous areas. Those were collected as an initial csv file from skiresort.info (this dataset is not available online anymore), and missing data was collected manually from Wikipedia.org. The resulting file was saved as ski.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning of dataframes: this step needs to be adapted to data sources and csv content. \n",
    "# Here the swiss_cities files were overwritten with the cleaned up version, so no need to run the following steps\n",
    "\n",
    "filepath = '../data/' # change to your local folder\n",
    "\n",
    "# swiss_cities should have index, city, lat, lng columns (if not, uncomment the cleaning lines)\n",
    "swiss_cities = pd.read_csv((filepath + 'swiss_cities.csv')) \n",
    "# ski_resorts should have index, city, lat, lng columns (if not, uncomment the cleaning lines)\n",
    "ski_resorts = pd.read_csv((filepath + 'ski.csv'))\n",
    "\n",
    "## swiss_cities cleaning (uncomment if necessary)\n",
    "# swiss_cities = swiss_cities.drop(columns ={'iso2', 'country', 'capital', 'population', 'population_proper', 'admin_name'})\n",
    "swiss_cities = swiss_cities[['city', 'lat', 'lng']]\n",
    "\n",
    "## ski_resorts cleaning\n",
    "# ski_resorts should have index, lng, lat, city columns\n",
    "ski_resorts = ski_resorts.rename(columns = {'X':'lng', 'Y':'lat', 'Name': 'city'})\n",
    "ski_resorts = ski_resorts.drop(columns = {'description'})\n",
    "ski_resorts = ski_resorts[['city', 'lat', 'lng']]\n",
    "\n",
    "\n",
    "# merging the two dataframes by concatenating them vertically\n",
    "cities_ski = pd.concat([swiss_cities, ski_resorts], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 177 entries, 0 to 176\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   city    177 non-null    object \n",
      " 1   lat     177 non-null    float64\n",
      " 2   lng     177 non-null    float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 4.3+ KB\n"
     ]
    }
   ],
   "source": [
    "cities_ski.info() # should have 177 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the dataframe as city_coord\n",
    "cities_ski.to_csv(filepath +'cities_ski_coord.csv', index = False) # has city, lat long in it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we still need to match the snow observation locations to the place's coordinated. We do that by merging the corresponding dataframes on the location names. Data will be lost when the names are not matching exaclty. As the number of errors is quite small (and we didn't know about regex yet), we dealt with that problem by filling the missing data by hand, and the complete dataframe for notebook is saved as snow_coordinates.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>location</th>\n",
       "      <th>height_in_m</th>\n",
       "      <th>snowlevel_in_cm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>La Chaux-de-Fonds</th>\n",
       "      <td>47.099600</td>\n",
       "      <td>6.829600</td>\n",
       "      <td>La Chaux-de-Fonds</td>\n",
       "      <td>1019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chur</th>\n",
       "      <td>46.852100</td>\n",
       "      <td>9.529700</td>\n",
       "      <td>Chur</td>\n",
       "      <td>555</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wädenswil</th>\n",
       "      <td>47.230300</td>\n",
       "      <td>8.672200</td>\n",
       "      <td>Wädenswil</td>\n",
       "      <td>463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nyon</th>\n",
       "      <td>46.382000</td>\n",
       "      <td>6.238900</td>\n",
       "      <td>Nyon</td>\n",
       "      <td>430</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Davos</th>\n",
       "      <td>46.809100</td>\n",
       "      <td>9.839800</td>\n",
       "      <td>Davos</td>\n",
       "      <td>1590</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Altdorf</th>\n",
       "      <td>46.880600</td>\n",
       "      <td>8.639400</td>\n",
       "      <td>Altdorf</td>\n",
       "      <td>449</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arosa</th>\n",
       "      <td>46.789611</td>\n",
       "      <td>9.638778</td>\n",
       "      <td>Arosa</td>\n",
       "      <td>1878</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Braunwald</th>\n",
       "      <td>46.938250</td>\n",
       "      <td>8.987139</td>\n",
       "      <td>Braunwald</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elm</th>\n",
       "      <td>46.929611</td>\n",
       "      <td>9.141028</td>\n",
       "      <td>Elm</td>\n",
       "      <td>965</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engelberg</th>\n",
       "      <td>46.790917</td>\n",
       "      <td>8.387722</td>\n",
       "      <td>Engelberg</td>\n",
       "      <td>1035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lenzerheide</th>\n",
       "      <td>46.746889</td>\n",
       "      <td>9.511556</td>\n",
       "      <td>Lenzerheide</td>\n",
       "      <td>1484</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lenzerheide</th>\n",
       "      <td>46.746889</td>\n",
       "      <td>9.511556</td>\n",
       "      <td>Lenzerheide</td>\n",
       "      <td>1484</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meiringen</th>\n",
       "      <td>46.737861</td>\n",
       "      <td>8.257361</td>\n",
       "      <td>Meiringen</td>\n",
       "      <td>595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zermatt</th>\n",
       "      <td>45.983056</td>\n",
       "      <td>7.782167</td>\n",
       "      <td>Zermatt</td>\n",
       "      <td>1638</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         lat       lng           location height_in_m  \\\n",
       "city                                                                    \n",
       "La Chaux-de-Fonds  47.099600  6.829600  La Chaux-de-Fonds        1019   \n",
       "Chur               46.852100  9.529700               Chur         555   \n",
       "Wädenswil          47.230300  8.672200          Wädenswil         463   \n",
       "Nyon               46.382000  6.238900               Nyon         430   \n",
       "Davos              46.809100  9.839800              Davos        1590   \n",
       "Altdorf            46.880600  8.639400            Altdorf         449   \n",
       "Arosa              46.789611  9.638778              Arosa        1878   \n",
       "Braunwald          46.938250  8.987139          Braunwald        None   \n",
       "Elm                46.929611  9.141028                Elm         965   \n",
       "Engelberg          46.790917  8.387722          Engelberg        1035   \n",
       "Lenzerheide        46.746889  9.511556        Lenzerheide        1484   \n",
       "Lenzerheide        46.746889  9.511556        Lenzerheide        1484   \n",
       "Meiringen          46.737861  8.257361          Meiringen         595   \n",
       "Zermatt            45.983056  7.782167            Zermatt        1638   \n",
       "\n",
       "                   snowlevel_in_cm  \n",
       "city                                \n",
       "La Chaux-de-Fonds                1  \n",
       "Chur                             0  \n",
       "Wädenswil                        0  \n",
       "Nyon                             0  \n",
       "Davos                           34  \n",
       "Altdorf                          0  \n",
       "Arosa                           51  \n",
       "Braunwald                        7  \n",
       "Elm                              0  \n",
       "Engelberg                        0  \n",
       "Lenzerheide                     22  \n",
       "Lenzerheide                     22  \n",
       "Meiringen                        0  \n",
       "Zermatt                          0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merging city_coordinates with snow data to create snow_coordinates_demo\n",
    "# this is a dummy df that only contains limited data for demonstration purposes. \n",
    "# In the next notebook we use the actual snow_coordinates df\n",
    "\n",
    "snow_level_coord = cities_ski.merge(snow_level_df, left_on = 'city', right_on= 'location')\n",
    "snow_level_coord = snow_level_coord.set_index('city').drop_duplicates()\n",
    "snow_level_coord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_ski2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow_level_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (223, 4), indices imply (219, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-e129f11fa468>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msnow_level_df2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msnow_level_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'location'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msnow_level_coord2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcities_ski2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msnow_level_df2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'outer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#snow_level_coord2 = snow_level_coord2.dropna()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msnow_level_coord2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    285\u001b[0m     )\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    500\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m             new_data = concatenate_block_managers(\n\u001b[0m\u001b[0;32m    503\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mblocks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;31m# Populate known_consolidate, blknos, and blklocs lazily\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mmgr_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtot_items\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (223, 4), indices imply (219, 4)"
     ]
    }
   ],
   "source": [
    "cities_ski3 = cities_ski.rename(columns={'city': 'location'})\n",
    "\n",
    "snow_level_coord3 = pd.concat([cities_ski3, snow_level_df], axis=1)\n",
    "#snow_level_coord2 = snow_level_coord2.dropna()\n",
    "snow_level_coord2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_level_coord = cities_ski.concat(snow_level_df, left_on = 'city', right_on= 'location')\n",
    "snow_level_coord = snow_level_coord.set_index('city').drop_duplicates()\n",
    "snow_level_coord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'snow_level_coord' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-89424edc5c1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# change the file_path to your path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'C:/Users/Malwina/Desktop/bergfex_snow_alert/data/snow_coordinates_test.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msnow_level_coord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'snow_level_coord' is not defined"
     ]
    }
   ],
   "source": [
    "# change the file_path to your path if necessary\n",
    "#file_path = '../data/'\n",
    "snow_level_coord.to_csv(file_path & 'snow_coordinates_demo.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTINUE IN NOTEBOOK III"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
